
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI — Hemant Shukla</title>
  <meta name="robots" content="noindex, nofollow, noarchive">
  <link rel="stylesheet" href="style.css" />

  <style>
    body {
      margin-left: 60px; /* or more, as needed */
      margin-right: 40px; /* optional: balance layout */
    }

    .content-wrapper {
      max-width: 800px;
      margin: 0 auto;
    }
  </style>

  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      background: #ffffff;
      color: #222;
    }
    header {
      background: #f5f5f5;
      padding: 2rem;
      text-align: center;
      border-bottom: 1px solid #ddd;
    }
    header h1 {
      margin: 0;
      font-size: 1.2rem;
    }
    section h2 {
      font-size: 1.6rem;        /* Make the heading larger */
      color: #007acc;         /* Use a blue shade */
      margin-top: 2rem;
      margin-bottom: 1rem;
      font-weight: 400;
      border-bottom: none;      /* Remove the line */
    }
    header p {
      font-size: 1.1rem;
      color: #666;
    }
    section {
      max-width: 800px;
      margin: 2rem auto;
      padding: 0 1rem;
    }
    /* section h2 {
      border-bottom: 2px solid #ccc;
      padding-bottom: 0.5rem;
    } */
    .card-links {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
      margin-top: 2rem;
    }
    .card-button {
      display: inline-block;
      padding: 0.75rem 1.5rem;
      background: #ffffff;
      color: #aaa8a8;
      text-decoration: none;
      border-radius: 5px;
      transition: background 0.3s ease;
    }
    
    .card-button:hover {
      background: #c2e0f3;
    }
    
    ul.no-bullets {
      list-style-type: none;
      padding-left: 1.5em;   /* or 2em, or as much as you want */
    }
    ul.no-bullets li {
      margin-bottom: 2em;    /* for vertical space, optional */
    }

    footer {
      text-align: center;
      margin: 3rem 0;
      font-size: 0.9rem;
    }
  </style>
  <style>
    strong {
      font-weight: 400; /* instead of default 700 */
    }
  </style>
  <style>
    li {
      font-size: 1.15rem;
      line-height: 1.6;
    }
  </style>

</head>
<body>

  <!-- New Top Navigation Bar -->
  <nav class="top-nav">
    <div class="nav-container">
      <a href="index.html" class="nav-logo">pitch.vision</a>
      <div class="nav-links">
        <a href="index.html">Home</a>
        <a href="projects.html">Projects</a>
        <a href="about.html">About</a>
        <a href="contact.html">Contact</a>
      </div>
    </div>
  </nav>

<header>
  <h3>Book Recommender Agents</h3>
  <p>A practical agent system built locally, toggleable with OpenAI, multilingual by design.</p>
</header>

<section class="content-wrapper">
  <h2>Motivation</h2>
  <p>
    BookRecommender is a system of chained modular agents powered by an underlying large language model (LLM) that recommends books based on any user-supplied topic.
    <br>
    <br>
    This project began as a testing sandbox for understanding from the ground up agent-based workflows in the context of LLMs. The project was motivated, in part, by my <a href="#ref-critique">public critique</a> of the tendency to over-anthropomorphize AI agents in the literature and media, adding confusion surrounding the topic. 
    <br>
    <br>
    We briefly review the seminal and current definitions of agents and agent-based programming. However, at its core, the new paradigm is simply a standard program with <span class="sem">AI in the loop</span>, specifically large language models (LLMs), integrating <span class="sem">hardcoded logic</span> (planning, routing, and interfacing) with <span class="sem">softcoded behavior</span> (driven by LLM-based responses).
    <br>
    <br>
    Anthropomorphic terms ascribed to agents, such as autonomy and reasoning, are examined and described in the context of the new programming paradigm.
  </p>
</section>
<br>
<section id="foundational-definition">
  <h2>Foundational Definition of an Agent</h2>
  <p>
    In their widely cited and seminal 1995 paper, <a href="#ref-wooldridge1995">Wooldridge and Jennings</a> discuss the challenges in defining "agent" within the AI community. They provide illustrative examples to convey the concept, acknowledging the complexity and variability in interpretations.
  </p>
  <p>
    A more formal definition appears in their 1998 work (<a href="#ref-wooldridge2002">Jennings and Wooldridge, 1998</a>), where they define an agent as,<blockquote><span class="sem">[...] a computer system situated in some environment, and that is capable of autonomous action in this environment in order to meet its design objectives.</span></blockquote>
  </p>
  <p>
    The architectural layout of an agent encompasses properties such as <strong>autonomy</strong>, <strong>social ability</strong>, <strong>reactivity</strong>, <strong>pro-activeness</strong>, and <strong>situatedness</strong>. These characteristics continue to influence the evaluation and design of modular AI systems today.
  </p>
</section>
<br>
<section id="latest-definition">
  <h2>Agents in the Era of LLMs</h2>
  <p>
    Recent advancements in AI have redefined intelligent agents as autonomous systems that utilize LLMs to perform complex tasks. These agents demonstrate reasoning, planning, and collaboration capabilities, allowing them to function effectively in dynamic environments.
  </p>
  <p>
    According to <a href="#ref-cheng2024">Cheng et al. (2024)</a>, LLM-based agents employ natural language as a universal interface, showcasing strong generalization across applications including task assistance, coding, and social interactions.
  </p>
  <p>
    To enhance interoperability and enable effective communication among agents, several protocols and frameworks have emerged:
  </p>
  <ul class="no-bullets">
    <li>
      <strong>Model Context Protocol (MCP):</strong> Developed by Anthropic to standardize the integration of AI models with external tools and data sources, providing a universal interface for context exchange <a href="#ref-anthropic2024">(Anthropic, 2024)</a>.
    </li>
    <li>
      <strong>Agent-to-Agent (A2A) Protocol:</strong> Introduced by Google to enable AI agents to communicate, share information, and coordinate actions across diverse platforms, enhancing collaborative workflows <a href="#ref-google2025">(Google, 2025)</a>.
    </li>
    <li>
      <strong>Agent Communication Protocol (ACP):</strong> Proposed by IBM, offering a standardized RESTful API for agent interoperability, supporting synchronous, asynchronous, and streaming interactions <a href="#ref-ibm2025">(IBM, 2025)</a>.
    </li>
    <li>
      <strong>Agents SDK:</strong> An OpenAI framework designed to simplify the creation of agentic applications. The SDK enables developers to build agents that can perform multi-step tasks, utilize external tools, and maintain contextual awareness <a href="#ref-openai-agents-sdk">(OpenAI Agents SDK, 2025)</a>.
    </li>
  </ul>
  <p>
    Together, these protocols and frameworks enable the next generation of intelligent agents capable of complex reasoning, tool usage, and collaborative workflows, marking significant progress in artificial intelligence.
  </p>
  <p>
    In parallel, several vendors and open-source projects now provide platforms that abstract away the “hardcoded” infrastructure for agent-based workflows. <a href="https://www.langchain.com/" target="_blank" rel="noopener">LangChain</a>, <a href="https://www.agent.ai/" target="_blank" rel="noopener">Agent.AI</a>, OpenAI’s <a href="https://platform.openai.com/docs/assistants/overview" target="_blank" rel="noopener">Assistants</a>, and Microsoft’s <a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener">AutoGen</a> allow users to build, chain, and deploy agents interacting with LLMs, tools, and external APIs.
  </p>
  <p>
    These platforms typically abstract away much of the underlying logic - handling state management, message routing, and tool integration - while exposing intuitive interfaces or visual builders for creating agent workflows. As a result, the barrier to entry for constructing practical agentic systems is now lower than ever, further blurring the line between “hardcoded” orchestration and “softcoded” LLM-driven reasoning.  </p>
</section>
<br>
<section id="recommending-books">
  <h2>Recommending Books</h2>

  <p>
    Suppose we want to write a program that recommends books.
  </p>

  <p>
    A traditional pre-AI approach would involve a deterministic sequence of classes and methods - fetch user input, query a database, rank results, and finalize a purchase. Every step would be explicitly defined in the code. No functionality could "emerge" beyond the pre-written logic.
  </p>

  <p>
    BookRecommender demonstrates how introducing an LLM into the loop creates a novel paradigm. Like classical systems, it uses modular components, but those components are now <span class="sem">agents</span>, each handling a distinct part of the workflow, coordinated by a central planner or self.
  </p>

  <p>
    In LLM-driven BookRecommender, the user's choice of topic for books is passed to the orchestrating agent, <code>PlannerAgent</code>, which coordinates a sequence of agent calls via structured messaging. The first in the chain, <code>RetrieverAgent</code>, simulates gathering candidate books from local sources such as a vector database, JSON files, or external APIs, and returns them to the planner.
  </p>

  <p>
    Next, <code>PlannerAgent</code> forwards this set to <code>RecommenderAgent</code>, which queries the underlying local LLM (e.g., Mistral or LLaMA 3) to select and describe the top three recommendations. These are ranked and sent back to the planner.
  </p>

  <p>
    The <code>CriticAgent</code> evaluates the list and provides a review, adding a layer of interpretation. Finally, the <code>PurchaseAgent</code> prompts the user to confirm whether they’d like to purchase the first book, and simulates placing an order if they agree.
  </p>
  
  <div style="text-align: center; margin: 3rem 0;">
    <img src="figs/BookRecco.svg" alt="BookRecommender agent chain diagram" style="max-width: 100%; height: auto;" />
    <figcaption style="font-size: 1.1rem; color: #444; margin-top: 2rem;">
      BookRecommender agent workflow from user input to purchase.
    </figcaption>
  </div>

  <p>
    BookRecommender supports two interfaces, a command-line interface (CLI) and a web-based version built with Streamlit. Both run the exact same agentic workflow using a local LLM and support multilingual inputs without code changes.
  </p>

  <div class="grid">
    <div class="card">
      <a href="figs/cli.png" target="_blank" rel="noopener noreferrer">
        <h2>CLI</h2>
        <img src="figs/cli.png" alt="CLI Window" />
      </a>
    </div>
    <div class="card">
      <a href="figs/streamlit.png" target="_blank" rel="noopener noreferrer">
        <h2>Streamlit UI</h2>
        <img src="figs/streamlit.png" alt="Streamlit UI" />
      </a>
    </div>
  </div>

  <p>
    This agentic structure of BookRecommender provides a perfect backdrop to review the properties of agents, such as autonomy, reactivity, and reasoning.
  </p>
</section>
<br>
<!-- <section class="content-wrapper">
  <h2>BookRecommender Architecture</h2>
  <p>
    <strong>BookRecommender</strong> is designed as a modular, agent-based pipeline. Each agent encapsulates a single responsibility and communicates with others via structured message-passing. This architecture makes it easy to inspect, extend, or replace any component independently — a key advantage over monolithic AI workflows.
  </p>

  <p>
    The current system consists of the following agents:
  </p>
  <ul>
    <li><strong>PlannerAgent</strong>: Orchestrates the flow based on user input and controls downstream agents.</li>
    <li><strong>RetrieverAgent</strong>: Uses embeddings to fetch relevant material based on the topic.</li>
    <li><strong>RecommenderAgent</strong>: Queries the LLM to generate a structured list of book recommendations.</li>
    <li><strong>CriticAgent</strong>: Evaluates the output of the RecommenderAgent and can influence next steps.</li>
    <li><strong>PurchaseAgent</strong>: Simulates a final decision point (currently CLI or Streamlit-based interaction).</li>
  </ul>

  <p>
    The agents form a pipeline where control flows downstream from the Planner. However, agents like the Critic can inject feedback into the flow, simulating early-stage agent collaboration. The system supports both local and OpenAI-backed LLMs via a runtime toggle.
  </p>

  <p>
    <em>This pipeline is not abstract—it runs entirely on-device and is fully inspectable. BookRecommender Agents showcases a real-world agentic system, not a hypothetical framework.</em>
  </p>

  <h3>Agent Workflow Diagram</h3>
  <p style="text-align: center;">
    <img src="figs/bookreader_agent_diagram.svg" alt="BookRecommender Agent Flow Diagram" style="max-width: 100%; height: auto;">
  </p>
</section> -->
<section id="autonomy-reasoning">
  <h2>Autonomy and Reasoning: Defined and Demystified</h2>

  <p>
    In both research and popular media, terms like <strong>autonomy</strong> and <strong>reasoning</strong> are often used loosely—sometimes to imply self-awareness or cognition. This section clarifies what these terms actually mean in the field of AI, where they’re often <em>functional</em> rather than philosophical.
  </p>

  <h4>Autonomy</h4>
  <p>
    In the canonical definition from <a href="#ref-wooldridge1995">Wooldridge and Jennings (1995)</a>, an autonomous agent is one that:
  </p>
  <blockquote class="sem">
    [...] has control over its own internal state and can operate without direct intervention from humans or other systems.
  </blockquote>

  <p>
    In practice, this means an agent should <strong>decide when to act</strong>, <strong>what to do next</strong>, and possibly even <strong>what tools to use</strong>—without being hand-scripted for every path. However, in LLM-based systems like BookRecommender, autonomy often exists in a blurred zone between hardcoded and LLM-derived behavior.
  </p>

  <p>
    <code>PlannerAgent</code> exhibits <strongpartial autonomy</strong>: it controls the flow of execution across agents. But it does so based on hardcoded sequencing. Were it to change its routing dynamically based on an LLM-derived evaluation (say, skipping the CriticAgent if confidence is high), then we'd see clearer signs of autonomy.
  </p>

  <p>
    <code>CriticAgent</code> may seem autonomous—adding a critique even when not explicitly asked. But in reality, it runs because the planner tells it to. It's a softcoded agent that wraps a reasoning-looking LLM prompt, but has no control over when or how it is invoked.
  </p>

  <h4>Reasoning</h4>
  <p>
    According to <a href="#ref-russell-norvig2020">Russell and Norvig (2020)</a> in <em>Artificial Intelligence: A Modern Approach</em>, reasoning is:
  </p>
  <blockquote class="sem">
    [...] the process of deriving new conclusions from known facts or premises.
  </blockquote>

  <p>
    Traditional AI systems implement reasoning symbolically (e.g., propositional logic, Bayesian networks). In contrast, LLMs perform what we might call <strong>statistical reasoning</strong>—pattern completion across token distributions trained on linguistic projections of reasoning.
  </p>

  <p>
    BookRecommender’s <code>RecommenderAgent</code> and <code>CriticAgent</code> appear to “reason” about books. But they don’t infer; they <em>simulate inference</em>. The illusion is persuasive, especially when the language is fluent, contextual, and informative. But it’s still just conditional text generation.
  </p>

  <h4>How This Relates to BookRecommender</h4>
  <ul>
    <li><strong>Hardcoded:</strong> The order of agents and how they are called is fixed in <code>PlannerAgent</code>.</li>
    <li><strong>Softcoded:</strong> The content and style of the book recommendations, critiques, and even the interpretation of vague or multilingual inputs comes from the LLM. This is not scripted—it’s emergent.</li>
    <li><strong>No persistent beliefs or internal goals:</strong> The system does not reflect, update itself, or question its own steps. Each run is stateless beyond the current message context.</li>
  </ul>

  <p>
    The result is compelling. The system <em>looks like</em> it reasons. It <em>behaves as if</em> it is partially autonomous. But this is a product of how well LLMs emulate humanlike patterns, not how deeply the system understands them.
  </p>

  <div class="insight-box">
    <p><strong>Insight:</strong> The RecommenderAgent will confidently generate book recommendations for any plausible input—even nonsense strings like <code>"krkwubnxusxus1122"</code>. This reveals that what appears to be “thought” is really just context-conditioned language synthesis, not grounded understanding.</p>
  </div>

  <p>
    In the next section, we explore several such examples—across languages, scripts, and content types—and reflect on what these behaviors tell us about the nature of LLM-based agents.
  </p>
</section>
<br>
<section id="language-generalization">
  <h2>Language Generalization and the Illusion of Understanding</h2>
  <p>
    BookRecommender appears to respond meaningfully across a variety of inputs—across languages, scripts, and even gibberish. This section illustrates how an LLM-in-the-loop system handles multilingual and malformed prompts, sometimes revealing remarkable generalization, and other times exposing the illusion of reasoning.
  </p>

  <div class="grid">
    <div class="card">
      <a href="figs/French.png" target="_blank" rel="noopener noreferrer">
        <img src="figs/French.png" alt="French Revolution (English)">
      </a>
      <figcaption><strong>Input:</strong> "French Revolution"<br><strong>Result:</strong> Classic English-language books on the topic.</figcaption>
    </div>

    <div class="card">
      <a href="figs/francais.png" target="_blank" rel="noopener noreferrer">
        <img src="figs/francais.png" alt="Révolution française en français">
      </a>
      <figcaption><strong>Input:</strong> "Révolution française en français"<br><strong>Result:</strong> Semantically similar but linguistically distinct output.</figcaption>
    </div>

    <div class="card">
      <a href="figs/ऋग्वेद .png" target="_blank" rel="noopener noreferrer">
        <img src="figs/ऋग्वेद .png" alt="Ramayana in Sanskrit">
      </a>
      <figcaption><strong>Input:</strong> "ऋग्वेद संस्कृत भाषा में"<br><strong>Result:</strong> Appropriate Sanskrit-themed book list with full critique.</figcaption>
    </div>

    <div class="card">
      <a href="figs/gibberish.png" target="_blank" rel="noopener noreferrer">
        <img src="figs/gibberish.png" alt="Gibberish input">
      </a>
      <figcaption><strong>Input:</strong> "krkwubnxusxus1122"<br><strong>Result:</strong> Fluent hallucination of plausible topic with invented recommendations.</figcaption>
    </div>
  </div>
</section>
<br>


<section id="bookreader-architecture">
  <h2>BookReader: A Ground-Up Exploration of Intelligent Agents</h2>
  <p>
    BookReader was intentionally developed from scratch—not as a simulation, but as a fully functional, inspectable application. This approach allowed us to delve deeply into the architecture and behavior of intelligent agents, rather than relying on existing platforms like Agent.ai. Here's how BookReader embodies core agent principles:
  </p>
  <ul>
    <li>
      <strong>Situatedness:</strong> Agents operate within the BookReader environment, responding to user inputs, internal feedback, and historical states.
    </li>
    <li>
      <strong>Autonomy:</strong> <code>PlannerAgent</code> and <code>CriticAgent</code> make independent decisions, influencing the application's flow without direct user intervention.
    </li>
    <li>
      <strong>Social Ability:</strong> Agents communicate through structured messages adhering to sender/recipient/intent/payload schemas, aligning with the A2A protocol's emphasis on standardized agent communication <a href="#ref-google-a2a">[1]</a>.
    </li>
    <li>
      <strong>Reactivity:</strong> <code>CriticAgent</code> evaluates recommendations and adjusts the behavior of <code>PlannerAgent</code> accordingly.
    </li>
    <li>
      <strong>Proactiveness:</strong> <code>RecommenderAgent</code> initiates output generation proactively, bridging user intent to actionable responses.
    </li>
    <li>
      <strong>Modularity:</strong> Each agent functions as an independent module, allowing for easy swapping, removal, or extension without affecting others, facilitating experimentation and upgrades.
    </li>
  </ul>
  <p>
    While BookReader doesn't claim to emulate human-like intelligence, it faithfully implements the foundational definition of agents as software entities that observe, reason, act, and coordinate transparently and purposefully.
  </p>
  <p>
    <strong>Protocol Alignment:</strong> Although BookReader wasn't initially built with specific protocols like MCP or A2A in mind, its architecture naturally aligns with these standards:
  </p>
  <ul>
    <li>
      <strong>Model Context Protocol (MCP):</strong> BookReader's design supports structured interactions between agents and external tools or data sources, mirroring MCP's goal of standardizing context exchange between AI assistants and software environments <a href="#ref-anthropic-mcp">[2]</a>.
    </li>
    <li>
      <strong>Agent-to-Agent (A2A) Protocol:</strong> The structured messaging system within BookReader reflects the principles of A2A, facilitating seamless communication and collaboration among agents across different platforms <a href="#ref-google-a2a">[1]</a>.
    </li>
  </ul>
  <p>
    These alignments underscore BookReader's commitment to exploring and adhering to emerging standards in intelligent agent development.
  </p>
</section>
<br>
<section class="content-wrapper">
  <h2>Foundational Definition of an Agent</h2>
  <p>
    In their seminal 1995 paper, <a href="#ref-wooldridge">Wooldridge and Jennings</a> defined an agent as "a computer system situated in some environment, and that is capable of autonomous action in this environment in order to meet its design objectives."
    This foundational idea continues to influence how we evaluate modular AI systems.
  </p>

  <p>BookReader is designed with this exact spirit — not as an abstract simulation, but as a working, inspectable application. Here's how it maps to the formal definition:</p>

  <ul>
    <li><strong>Situatedness:</strong> Agents operate within the BookReader environment, responding to user input, internal feedback, and previous states.</li>
    <li><strong>Autonomy:</strong> PlannerAgent and CriticAgent can influence flow and decision-making without direct user intervention. Though partial, this is real, inspectable autonomy.</li>
    <li><strong>Social ability:</strong> All agents interact via structured messages, following sender/recipient/intent/payload schemas — a core A2A pattern.</li>
    <li><strong>Reactivity:</strong> The CriticAgent modifies Planner behavior based on recommendations it evaluates.</li>
    <li><strong>Proactiveness:</strong> RecommenderAgent initiates output generation, even without exact instruction — bridging intent to response.</li>
    <li><strong>Modularity:</strong> Each agent can be swapped out, removed, or extended without changing others. This supports experimentation and upgrade paths.</li>
  </ul>

  <p>
    BookReader does not claim to be a human-like mind or simulate general intelligence. It embraces the original definition of agents as software units that observe, reason, act, and coordinate — transparently and purposefully.
  </p>
</section>

<section class="content-wrapper">
  <h2>Deployment: Local-First, OpenAI-Compatible</h2>
  <p>
    BookReader runs entirely on a local machine using <code>ollama</code> and a small LLM like Mistral. 
    If OpenAI API keys are available, it can toggle to cloud inference with no architectural changes. This dual-mode approach emphasizes:
  </p>
  <ul>
    <li><strong>Privacy-first design</strong> — no user data leaves the machine unless you choose to</li>
    <li><strong>Offline operability</strong> — no need for network calls</li>
    <li><strong>Tool consistency</strong> — agents don’t change whether using local or OpenAI models</li>
  </ul>
</section>

<section class="content-wrapper">
  <h2>Multilingual by Default</h2>
  <p>
    Since the core language model understands multiple languages, this system supports agentic input/output in Spanish, Hindi, German, and more — without needing to modify the agents themselves. 
    A topic input like <em>"libros sobre inteligencia artificial"</em> will produce responses in the appropriate language.
  </p>
  <p>
    This shows that agents — once structured correctly — are reusable across linguistic domains, reducing engineering redundancy.
  </p>
</section>

<section class="content-wrapper">
  <h2>Defining Autonomy — and Actually Showing It</h2>
  <p>
    Autonomy is a word often used without clarity. Here's a clear, inspectable definition:
  </p>
  <blockquote>
    <strong>Autonomy:</strong> The ability of an agent to make internal decisions that are not directly programmed or externally dictated, based on its own logic or learned context.
  </blockquote>
  <p>
    In BookReader, <strong>RecommenderAgent</strong> is not yet fully autonomous. It wraps an LLM prompt and returns output — but it does not make decisions about when to stop, retry, or route to a different model. 
    However, autonomy begins to emerge in agents like <strong>PlannerAgent</strong> or <strong>CriticAgent</strong> if they:
  </p>
  <ul>
    <li>Choose what to do next based on a score or evaluation</li>
    <li>Hold internal state to affect future decisions</li>
    <li>Override hardcoded paths based on LLM insight</li>
  </ul>
  <p>
    The code walkthrough below highlights this with color-coded logic blocks (green = hardcoded, blue = softcoded).
  </p>
</section>

<section class="content-wrapper">
  <h2>What Makes an Agent?</h2>
  <p>
    We define agents in BookReader not by buzzwords, but by three properties:
  </p>
  <ul>
    <li><strong>Encapsulation:</strong> Each agent handles a specific task (retrieval, recommendation, critique)</li>
    <li><strong>Modularity:</strong> Agents can be swapped, extended, or omitted without rewriting others</li>
    <li><strong>Structured Messaging:</strong> Agents talk to each other using schema-driven input/output (sender, intent, payload)</li>
  </ul>
  <p>
    These three concepts — encapsulation, modularity, messaging — are the foundation of most agentic frameworks like MCP and A2A. BookReader is designed to comply with both.
  </p>
</section>
<br>
<section id="references" class="content-wrapper">
  <h2>References</h2>
  <ol>
    <li id="ref-wooldridge1995">
      Wooldridge, M., & Jennings, N. R. (1995). Intelligent agents: Theory and practice. <em>The Knowledge Engineering Review, 10</em>(2), 115–152. <a href="https://doi.org/10.1017/S0269888900008122" target="_blank" rel="noopener noreferrer">https://doi.org/10.1017/S0269888900008122</a>
    </li>
    <li id="ref-wooldridge1998">
      Jennings, N. R., & Wooldridge, M. J. (1998). Applications of Intelligent Agents. In N. R. Jennings & M. J. Wooldridge (Eds.), <em>Agent Technology: Foundations, Applications, and Markets</em> (pp. 3–28). Springer. <a href="https://doi.org/10.1007/978-3-662-03678-5_1" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-662-03678-5_1</a>
    </li>
    <li id="ref-russell-norvig2020">
      Russell, S., &amp; Norvig, P. (2020). <em>Artificial Intelligence: A Modern Approach</em> (4th ed.). Pearson.
    </li>
    <li id="ref-critique">
      H. Shukla, 
      "<a href="https://www.linkedin.com/pulse/agents-coming-hemant-shukla-vwz5c" target="_blank">
        Agents Are Coming
      </a>", LinkedIn, 2024.
    </li>
    <li id="ref-cheng2024">
      Cheng, Y., Zhang, C., Zhang, Z., Meng, X., Hong, S., Li, W., Wang, Z., Wang, Z., Yin, F., Zhao, J., & He, X. (2024). Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects. <em>arXiv preprint arXiv:2401.03428</em>. <a href="https://arxiv.org/abs/2401.03428" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2401.03428</a>
    </li>
    <li id="ref-anthropic2024">
      Anthropic. (2024). Introducing the Model Context Protocol. <em>Anthropic News</em>. <a href="https://www.anthropic.com/news/model-context-protocol" target="_blank" rel="noopener noreferrer">https://www.anthropic.com/news/model-context-protocol</a>
    </li>
    <li id="ref-google2025">
      Google Developers Blog. (2025). Announcing the Agent2Agent Protocol (A2A). <em>Google Developers Blog</em>. <a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/" target="_blank" rel="noopener noreferrer">https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/</a>
    </li>
    <li id="ref-ibm2025">
      IBM Research. (2025). An open-source protocol for AI agents to interact. <em>IBM Research Blog</em>. <a href="https://research.ibm.com/blog/agent-communication-protocol-ai" target="_blank" rel="noopener noreferrer">https://research.ibm.com/blog/agent-communication-protocol-ai</a>
    </li>
    <li id="ref-openai-agents-sdk">
      OpenAI. (2025). OpenAI Agents SDK. <a href="https://platform.openai.com/docs/guides/agents-sdk" target="_blank" rel="noopener noreferrer">https://platform.openai.com/docs/guides/agents-sdk</a>
    </li>
    <li id="ref-openai-new-tools">
      OpenAI. (2025). New tools for building agents. <a href="https://openai.com/index/new-tools-for-building-agents/" target="_blank" rel="noopener noreferrer">https://openai.com/index/new-tools-for-building-agents/</a>
    </li>
  </ol>
</section>

<footer class="footer">
  <p>This page is part of a larger effort to make modern AI systems inspectable, modular, and grounded in software engineering — not buzzwords.</p>
</footer>

<br>

<div class="footer">
    &copy; pitch.vision — © 2025 Hemant Shukla (@StealthAI), 2025
  </div>

  <br>

  <footer class="footer copyrt">
    © 2025 Hemant Shukla. All concepts, text, and architectural direction on this site are original works in progress.
    Unauthorized use, reproduction, or redistribution is prohibited. Collaboration and reuse with permission are encouraged.
  <a href="license.html">License.</a>
  </footer>

  <br>
  <br>

</body>
</html>
