<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI — Hemant Shukla</title>
  <meta name="robots" content="noindex, nofollow, noarchive">
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <!-- Navigation Bar -->
  <nav class="top-nav">
    <div class="nav-container">
      <a href="index.html" class="nav-logo">pitch.vision</a>
      <div class="nav-links">
        <a href="index.html">Home</a>
        <a href="projects.html">Projects</a>
        <a href="about.html">About</a>
        <a href="contact.html">Contact</a>
      </div>
    </div>
  </nav>

  <div class="main-content" id="mainContent">
    <div class="container">
      <center>
        <h1>Rare Event Detection with MLP-SNN</h1>
        <h2>Low-Data, High-Sparsity Learning from CHB-MIT Signals</h2>
        <p>Exploring data-imbalance, confidence, and spiking architectures</p>
      </center>

      <br><br>

      <div class="content-wrapper">

        <h3>Problem Motivation</h3>
        <p>  
          Complementary to the SNN-RPi project, this effort explores how learning can occur in sparse environments with limited data and low signal density. It demonstrates how biologically-inspired architectures like SNNs can extract meaning even when examples are scarce.
        </p>
        <ul>
          <li>Can spiking networks learn from as little as 10 positive samples?</li>
          <li>How does model confidence degrade as class imbalance increases?</li>
          <li>How do MLPs compare to MLP+SNN hybrids under these constraints?</li>
        </ul>

        <h3>Dataset</h3>
        <p>
          We used publicly available CHB-MIT temporal signal data — originally captured in .edf format and converted into PyTorch tensors. Events (formerly labeled “seizures”) are rare and represent under 1% of total samples, introducing natural imbalance.
        </p>
        <div class="grid">
          <a href="figs/class-0.png" target="_blank" class="card-link">
            <div class="card">
            <h2>Class 0 (no event)</h2>
            <img src="figs/class-0.png" alt="">
            </div>
          </a>
        </div>
        <div class="grid">
          <a href="figs/class-1.png" target="_blank" class="card-link">
            <div class="card">
            <h2>Class 1 (event)</h2>
            <img src="figs/class-1.png" alt="">
            </div>
          </a>
        </div>

        <h3>Experimental Conditions</h3>
        <p>
          We tested three dataset variants:
        </p>
        <ul>
          <li><b>Balanced</b>: 250 event / 250 non-event</li>
          <li><b>Mildly imbalanced</b>: 50 event / 250 non-event</li>
          <li><b>Severely imbalanced</b>: 10 event / 200 non-event</li>
        </ul>

        <h3>Models Compared</h3>
        <ul>
          <li><b>Vanilla MLP</b>: 2-layer linear model</li>
          <li><b>MLP + SNN</b>: same MLP, gated with spiking dynamics</li>
        </ul>

        <h3>Metrics Tracked</h3>
        <ul>
          <li>Train/Test Accuracy</li>
          <li>Loss curve</li>
          <li>Model confidence</li>
          <li>Prediction entropy</li>
          <li>Class-weighted loss</li>
        </ul>

        <h3>Results Overview</h3>

        <div class="content-block">
          <h3>Performance Summary</h3>
          <table class="styled-table">
            <thead>
              <tr>
                <th>Metric</th>
                <th>MLP-SNN (250:250)</th>
                <th>MLP Only (250:250)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Accuracy</td>
                <td>100.00%</td>
                <td>100.00%</td>
              </tr>
              <tr>
                <td>Confidence (softmax)</td>
                <td>~0.69</td>
                <td>1.00</td>
              </tr>
              <tr>
                <td>Entropy (nats)</td>
                <td>~0.65</td>
                <td>~0.0</td>
              </tr>
              <tr>
                <td>Logit Spread</td>
                <td>Moderate</td>
                <td>Peaked near 1.0</td>
              </tr>
              <tr>
                <td>Overfitting Risk</td>
                <td>Lower</td>
                <td>High (overconfident)</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="grid">
          <a href="figs/entropy.png" target="_blank" class="card-link">
            <div class="card">
            <h2>Entropy</h2>
            <img src="figs/entropy.png" alt="">
            </div>
          </a>
          <a href="figs/logit.png" target="_blank" class="card-link">
            <div class="card">
            <h2>Logits</h2>
            <img src="figs/logit.png" alt="">
            </div>
          </a>
        </div>
       <div class="content-block">
          <h3>Entropy of Softmax Predictions</h3>
          <p>
            This plot shows the entropy of the model’s softmax output across the test set. Entropy measures predictive uncertainty.
            A value near <code>ln(2) ≈ 0.6931</code> is the theoretical maximum for binary classification — indicating total uncertainty (i.e., 50/50 confidence).
          </p>
          <p>
            Our model’s entropy peaks around <strong>0.65</strong>, meaning it's making somewhat confident but not overconfident predictions.
            This suggests the model understands signal ambiguity and avoids brittle yes/no guesses.
          </p>
        </div>

        <div class="content-block">
          <h3>Logit Distribution</h3>
          <p>
            This plot shows the raw logits (pre-softmax outputs) from the model. Logits indicate how strongly the model favors one class.
            A logit near 0.0 means the model is undecided; a value near 1.0 suggests high confidence.
          </p>
          <p>
            We see a wide spread of logits, with a large concentration near zero and some around 0.7–0.8.
            This aligns with the entropy curve and shows the model isn't forcing sharp decisions — a behavior that reduces overfitting.
          </p>
        </div>
        
        <h3>Observations</h3>
        <ul>
          <li>Both MLP and SNN achieve perfect accuracy on balanced datasets</li>
          <li>MLP shows overconfidence (confidence ~1.00), SNN stabilizes near ln(2)</li>
          <li>As imbalance worsens, model entropy remains low — indicating potential learning collapse</li>
        </ul>

        <h3>Limitations</h3>
        <ul>
          <li>Perfect accuracy may be a red flag — especially under extreme imbalance</li>
          <li>Full dataset is <b>too imbalanced</b> to use without sampling</li>
          <li>Current evaluations lack out-of-distribution (OOD) generalization check</li>
        </ul>

        <h3>What's Next</h3>
        <ul>
          <li>Add more spiking depth (fc-lif-fc-lif)</li>
          <li>Train with label smoothing or entropy penalties</li>
          <li>Compare with a fully spiking network (SNN only)</li>
          <li>Test OOD generalization using other chbXX files not used in training</li>
        </ul>

        <br>
        <p><em>This is ongoing work. All results are preliminary. Final evaluation will include visualization of spike activity, timing breakdowns, and generalization.</em></p>

      </div>

      <br><br>
    </div>
  </div>

<div class="footer">Part of the <em>safe, adaptive, energy-efficient, personalized</em> AI project.</div>

<div class="footer">
    &copy; pitch.vision — © 2025 Hemant Shukla (@StealthAI), 2025
  </div>
  <br>
  <footer class="footer copyrt">
    © 2025 Hemant Shukla. All concepts, text, and architectural direction on this site are original works in progress.
    Unauthorized use, reproduction, or redistribution is prohibited. Collaboration and reuse with permission are encouraged.
  <a href="license.html">License.</a>
  </footer>

</body>
</html>


<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MLP-SNN for Seizure Detection</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="container">
    <h1>MLP-SNN for Seizure Detection</h1>
    <p class="tagline">A spiking neural network trained on EEG signals with high efficiency and rapid convergence.</p>

    <section>
      <h2>Motivation</h2>
      <p>
        Epileptic seizure detection from EEG data is a critical real-world challenge. While conventional neural networks
        and transformers have shown promise, they are often computationally heavy and data-hungry. This project explores
        whether a lightweight multi-layer perceptron using spiking neurons (MLP-SNN) can detect seizures with high
        efficiency, low power, and minimal data.
      </p>
    </section>

    <section>
      <h2>Architecture</h2>
      <p>This model uses an MLP-style SNN with two fully connected layers and Leaky Integrate-and-Fire dynamics.</p>
      <div class="image-placeholder">[Insert SVG architecture diagram here]</div>
    </section>

    <section>
      <h2>Results</h2>
      <ul>
        <li>Trained on 200 balanced samples from CHB-MIT EEG dataset</li>
        <li>Reached ~69% confidence with only 3 epochs</li>
        <li>Full training time under 1 minute on a MacBook M2 Max</li>
        <li>No pretraining, no convolutions, no data augmentation</li>
      </ul>
      <div class="image-placeholder">[Insert confidence histogram here]</div>
      <div class="image-placeholder">[Insert logits distribution plot here]</div>
      <div class="image-placeholder">[Insert accuracy vs data size curve here]</div>
    </section>

    <section>
      <h2>Comparison with Other Approaches</h2>
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Type</th>
            <th>Accuracy</th>
            <th>Data Used</th>
            <th>Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>MLP-SNN (this work)</td>
            <td>Spiking MLP</td>
            <td>~69%</td>
            <td>200 samples</td>
            <td>Fast convergence (3 epochs)</td>
          </tr>
          <tr>
            <td>Ahmad et al. (2023)</td>
            <td>Hybrid CNN-LSTM</td>
            <td>95.3%</td>
            <td>12,000 samples</td>
            <td>Heavy preprocessing + augmentation</td>
          </tr>
          <tr>
            <td>Other SOTA</td>
            <td>[TBD]</td>
            <td>[TBD]</td>
            <td>[TBD]</td>
            <td>[TBD]</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section>
      <h2>Scientific Significance</h2>
      <p>
        We believe this is the first public demonstration of an MLP-style SNN trained on real-world EEG seizure data.
        Unlike other deep models, it achieves moderate accuracy with minimal data and compute. The result offers a
        practical SNN benchmark for neuromorphic hardware or real-time healthcare applications.
      </p>
    </section>

    <section>
      <h2>Next Steps</h2>
      <ul>
        <li>Train on full CHB-MIT dataset (10k+ samples)</li>
        <li>Deploy on Raspberry Pi with real-time signal</li>
        <li>Compare against ConvSNN and transformer-based EEG models</li>
        <li>Submit paper once validation and benchmark are complete</li>
      </ul>
    </section>

    <section>
      <h2>References</h2>
      <ol>
        <li>Ahmad, M. et al. (2023). "A hybrid deep learning model for epileptic seizure detection." Biomedical Signal Processing</li>
        <li>CHB-MIT Scalp EEG Database: <a href="https://physionet.org/content/chbmit/1.0.0/">PhysioNet</a></li>
      </ol>
    </section>
  </div>
</body>
</html>
 -->
